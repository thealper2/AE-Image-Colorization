{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac307b5-db0b-4abf-b6e7-9950cd11cba6",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27ad12-90ff-44dd-b0c3-a90b1c0fe773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import plot_model, img_to_array\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761aef3c-2193-468d-8f4b-f4cdfec2ff5b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92382e8-1ab4-4f35-9ee3-e39ed850802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images_path = \"/mnt/d/Datasets/landscape Images/color\"\n",
    "gray_images_path = \"/mnt/d/Datasets/landscape Images/gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5f0d6-f310-4ad7-8bcd-3d963bcf5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size=224, count=1000):\n",
    "    files = os.listdir(path)[:count]\n",
    "    images = []\n",
    "\n",
    "    for file in tqdm.tqdm(files):\n",
    "        img_path = os.path.join(path, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (size, size))\n",
    "        img = img.astype(\"float32\") / 255.\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b971a4-1367-4a6a-946e-1c1ae1e4cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "count = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04782f48-4ca4-4369-99b1-7571352ad7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images = load_images(rgb_images_path, size, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4005f9-68c8-457b-8250-73d5d119a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = load_images(gray_images_path, size, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eabc25-f6bd-4256-af03-b39e42bf53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.95\n",
    "train_rgb_images = rgb_images[:int((len(rgb_images) * train_size))]\n",
    "test_rgb_images = rgb_images[int((len(rgb_images) * train_size)):]\n",
    "train_gray_images = gray_images[:int((len(gray_images) * train_size))]\n",
    "test_gray_images = gray_images[int((len(gray_images) * train_size)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2884dcf-632a-410f-80fc-b0c17255fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rgb_images\n",
    "del gray_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37736d0a-de1f-4373-8e0f-86f31f2afe60",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88330cee-73d6-4bf7-bb8b-f9b1032b6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "\n",
    "axes[0].imshow(train_rgb_images[10])\n",
    "axes[0].set_title(\"RGB Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(train_gray_images[10])\n",
    "axes[1].set_title(\"Gray Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857c957-23dd-4c1c-a371-f5a0be6a7579",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a706a-ac1d-4a88-ac7b-05b8ba53f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size, apply_batch_normalization=True):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', strides=2)(x)\n",
    "    if apply_batch_normalization:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358206f-6aeb-4040-a650-f95d362906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(x, skip, filters, kernel_size, dropout=False):\n",
    "    x = layers.Conv2DTranspose(filters, kernel_size, padding='same', strides=2)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.concatenate([x, skip])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02deb3-10e9-41c6-9517-79dd262a2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(size):\n",
    "    inputs = layers.Input(shape=[size, size, 3])\n",
    "\n",
    "    # Downsampling\n",
    "    d1 = down_block(inputs, 128, (3, 3), apply_batch_normalization=False)\n",
    "    d2 = down_block(d1, 128, (3, 3), apply_batch_normalization=False)\n",
    "    d3 = down_block(d2, 256, (3, 3), apply_batch_normalization=True)\n",
    "    d4 = down_block(d3, 512, (3, 3), apply_batch_normalization=True)\n",
    "    d5 = down_block(d4, 512, (3, 3), apply_batch_normalization=True)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = up_block(d5, d4, 512, (3, 3), dropout=False)\n",
    "    u2 = up_block(u1, d3, 256, (3, 3), dropout=False)\n",
    "    u3 = up_block(u2, d2, 128, (3, 3), dropout=False)\n",
    "    u4 = up_block(u3, d1, 128, (3, 3), dropout=False)\n",
    "\n",
    "    # Final upsampling\n",
    "    u5 = layers.Conv2DTranspose(64, (3, 3), padding='same', strides=2)(u4)\n",
    "    u5 = layers.LeakyReLU()(u5)\n",
    "    u5 = layers.concatenate([u5, inputs])\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid', padding='same')(u5)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c9fb8-a455-4019-81aa-4b735ce1fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df72db-b790-4409-ba46-87f47f1f0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80305c10-a9c7-4371-b33d-b5a5ae30d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259360ed-ebb5-4037-99e5-50f21e8bf4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001),\n",
    "    loss = \"mean_absolute_error\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93414f9e-3a04-4059-82b1-17310dcef55f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e0fc9-4f19-4f9b-a2e8-534c0c32b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gray_images,\n",
    "    train_rgb_images,\n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    validation_data=(test_gray_images, test_rgb_images),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65159a-fa0a-44f7-8e92-31bc8ab0eaa3",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37099fdf-7b82-4e5c-89b8-c3ba45e8c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc574b9e-3f4c-4aa7-b77e-b1dd3cab6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"valid\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2ca51-1959-4c40-9a6e-4d86cb9b3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"valid\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76946e-ada5-4753-bcb5-cd65db11ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(test_rgb, test_gray, count=25, size=224):\n",
    "    for _ in range(count):\n",
    "        random_idx = np.random.randint(len(test_rgb))\n",
    "        predicted = model.predict(test_rgb[random_idx].reshape(1, size, size, 3), verbose=0)\n",
    "        predicted = np.clip(predicted, 0.0, 1.0).reshape(size, size, 3)\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))\n",
    "        \n",
    "        axes[0].imshow(test_rgb[random_idx])\n",
    "        axes[0].set_title(\"RGB Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        axes[1].imshow(test_gray[random_idx])\n",
    "        axes[1].set_title(\"Gray Image\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        axes[2].imshow(predicted)\n",
    "        axes[2].set_title(\"Predicted Image\")\n",
    "        axes[2].axis(\"off\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2f7ec-a469-4af4-b45b-3775929addc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_images(test_rgb_images, test_gray_images, count=5, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d3a40-9cea-4ccb-a663-2c0a823b2f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
